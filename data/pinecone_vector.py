import os
from typing import List
from dotenv import load_dotenv
from pinecone import Pinecone
from langchain_openai import OpenAIEmbeddings
from langchain.schema import Document

# .env deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv()

# Pinecone baÄŸlantÄ±sÄ±
pinecone_api_key = os.getenv("PINECONE_API_KEY")
index_name = os.getenv("PINECONE_INDEX_NAME")

pc = Pinecone(api_key=pinecone_api_key)
index = pc.Index(host="https://meal-data-2-ac7k9cs.svc.aped-4627-b74a.pinecone.io")

# Embeddings
embeddings_model = OpenAIEmbeddings(
    model="text-embedding-3-small",
    api_key=os.getenv("OPENAI_API_KEY")
)

def upload_documents_to_pinecone(documents: List[Document], batch_size: int = 100):

    #  oluÅŸan chunklarÄ±n her birinin page_content ini alÄ±p embed ediyor
    vectors = embeddings_model.embed_documents([doc.page_content for doc in documents])
    
    # 2. pinecon formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz
    items = [
        (str(doc.metadata["meal_id"]), vector, doc.metadata)
        for doc, vector in zip(documents, vectors)
        
    ]
    
    # Ä°tems listesini batch'ler halinde  pinecone a yÃ¼kle
    for i in range(0, len(items), batch_size):
        batch = items[i:i+batch_size]
        index.upsert(vectors=batch)
        print(f"âœ… {len(batch)} dÃ¶kÃ¼man batch olarak yÃ¼klendi (Batch {i//batch_size + 1})")
    
    print(f"ğŸ‰ Toplam {len(items)} dÃ¶kÃ¼man Pinecone'a yÃ¼klendi.")

def load_existing_vector_store() -> bool:
    try:
        stats = index.describe_index_stats()
        vector_count = stats.get("total_vector_count", 0)
        
        if vector_count > 0:
            print(f"ğŸ“Š VeritabanÄ±nda {vector_count} adet tarif zaten mevcut. Veri Ã§ekme iÅŸlemi atlanÄ±yor.")
            return True
        else:
            print("â³ VeritabanÄ± boÅŸ. Veri Ã§ekme ve yÃ¼kleme iÅŸlemi baÅŸlatÄ±lÄ±yor...")
            return False

    except Exception as e:
        print(f"âŒ Pinecone ile iletiÅŸimde bir hata oluÅŸtu: {e}")
        return False
